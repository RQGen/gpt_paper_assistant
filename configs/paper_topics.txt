 1. New systems or methods regarding using LLMs in many application scenarios, especially in improving researchers' skill or process of research.
    - Relevant: HCI papers, especially system works, that discusses LLM application in research or science of science.
    - Not relevant: papers that are for general application.
 2. New methodological improvements to RLHF or instruction-following which are specific fine-tuning steps that are taken to make language models better at following user instructions across a range of tasks.
    - Relevant: papers that discuss specific methods like RLHF, or instruction-tuning datasets, improving these methods, or analyzing them. Usually these papers will explicitly mention RLHF, instruction-following or instruction-tuning.
    - Not relevant: papers about adaptation to some task. Simply following instructions or inputs are not sufficient.
 3. Describes new paradigms to evaluating open-ended text generation. Evaluating the outputs of language models is hard, especially in open-ended settings like for chatbots.
    - Relevant: papers that fundamentally rethink language model evaluation -- especially by accounting for subjectivity or using adversaries.
    - Not relevant: specific evaluations for specific tasks, identifying new properties or flaws of language models, or simply collecting new data.
 4. Conducts surveys or provides data into real-world usage and safety properties of language models.
    - Relevant: papers that create new datasets or surveys on real-world usage of language models.
    - Not relevant: papers that apply language models to new real-world tasks.

 In suggesting papers to your friend, remember that he enjoys papers on human computer interaction and designs using LLMs, especially those related to "science of science".
 Your friend also likes learning about surprising empirical results in language models, as well as clever statistical tricks.